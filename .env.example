# ARL Environment Configuration

# ==========================================
# LLM Provider Configuration
# ==========================================

# Default provider: google, azure, anthropic, ollama
# LLM_PROVIDER=google

# Google AI (Gemini)
# GOOGLE_API_KEY=your_google_api_key_here

# Azure OpenAI
# AZURE_OPENAI_API_KEY=your_azure_api_key_here
# AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2024-02-15-preview
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4  # Your deployment name in Azure Portal

# Anthropic (Claude)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ==========================================
# Database Configuration
# ==========================================

# DATABASE_URL=sqlite:///./data/arl.db

# ==========================================
# Application Settings
# ==========================================

# DEBUG=false
# LOG_LEVEL=INFO
# APP_NAME=ARL

# ==========================================
# External APIs
# ==========================================

# ARXIV_API_ENABLED=true
# PUBMED_API_KEY=your_pubmed_api_key_here

# ==========================================
# Execution Settings
# ==========================================

# DOCKER_ENABLED=true
# MAX_CONCURRENT_EXPERIMENTS=3
# EXPERIMENT_TIMEOUT_SECONDS=600

# ==========================================
# Storage Settings
# ==========================================

# DATA_DIR=./data
# PROJECTS_DIR=./data/projects
# ARTIFACTS_DIR=./data/artifacts

# ==========================================
# Memory Backend
# ==========================================

# MEMORY_BACKEND=local  # local or vertex
# VERTEX_PROJECT_ID=your_gcp_project_id
# VERTEX_LOCATION=us-central1

# ==========================================
# Deployment Mode
# ==========================================

# DEPLOYMENT_MODE=local  # local, cloud, or hybrid

# ==========================================
# A2A Protocol Configuration
# ==========================================

# Enable A2A protocol for agent-to-agent communication
# Default: false (agents run in same process)
# ARL_A2A_ENABLED=false

# Deployment mode: local, remote, or hybrid
# - local: All agents in same process (no A2A)
# - remote: All agents as separate A2A servers
# - hybrid: Mix of local and remote agents
# ARL_A2A_DEPLOYMENT_MODE=local

# Server host for A2A agents
# ARL_A2A_HOST=0.0.0.0

# Base port for A2A agents (each agent gets base_port + offset)
# Hypothesis: 8100, Experiment: 8101, CodeGen: 8102, Execution: 8103, Analysis: 8104
# ARL_A2A_BASE_PORT=8100

# Authentication scheme: none, bearer, api_key, oauth2
# ARL_A2A_AUTH_SCHEME=none

# API Key (if using api_key auth scheme)
# ARL_A2A_API_KEY=your-secret-key

# Bearer Token (if using bearer auth scheme)
# ARL_A2A_BEARER_TOKEN=your-bearer-token

# Request timeout in seconds
# ARL_A2A_TIMEOUT_SECONDS=300

# Maximum retry attempts for failed requests
# ARL_A2A_MAX_RETRIES=3

# Agent card storage directory
# ARL_A2A_AGENT_CARDS_DIR=./data/agent_cards

# ==========================================
# A2A Hybrid Mode Configuration
# ==========================================
# (Only used when ARL_A2A_DEPLOYMENT_MODE=hybrid)

# Custom URLs for remote agents (leave blank to use local)
# ARL_A2A_HYPOTHESIS_AGENT_URL=http://remote-server:8100
# ARL_A2A_EXPERIMENT_AGENT_URL=http://remote-server:8101
# ARL_A2A_CODE_GEN_AGENT_URL=http://remote-server:8102
# ARL_A2A_EXECUTION_AGENT_URL=http://remote-server:8103
# ARL_A2A_ANALYSIS_AGENT_URL=http://remote-server:8104
